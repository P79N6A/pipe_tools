{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test, then Write pipeline output module function to compare successive runs of a pipeline.\n",
    "\n",
    "* Suspended development at 17:00 one day -- in process of developing means of module_list_view:\n",
    "    * functions\n",
    "    * code\n",
    "    * header\n",
    "    * main (if it exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/pipeline_output_check.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ../src/pipeline_output_check.py\n",
    "import os\n",
    "import sys\n",
    "import filecmp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ignore_list = ['head', 'show_functions', 'header']\n",
    "\n",
    "def head():\n",
    "    file_name = os.path.join(os.getcwd(), 'pipeline_output_check.py')\n",
    "    function_dict = get_functions_dict(file_name)\n",
    "    for fn, fn_def in function_dict.items():\n",
    "        if fn == 'header':\n",
    "            print('\\n%60s\\n\\n%s'%(fn, fn_sig))\n",
    "            \n",
    "def show_functions(show_defs=False):\n",
    "    \"\"\" Usage: show_functions(show_defs)\n",
    "    Args:       show_defs False is default\n",
    "    \"\"\"\n",
    "    file_name = os.path.join(os.getcwd(), 'pipeline_output_check.py')\n",
    "    function_dict = get_functions_dict(file_name)\n",
    "    if show_defs == False:\n",
    "        for fn, fn_def in function_dict.items():\n",
    "            if fn == 'header':\n",
    "                pass\n",
    "            else:\n",
    "                print(fn)\n",
    "    else:\n",
    "        for fn, fn_def in function_dict.items():\n",
    "            if fn in ignore_list:\n",
    "                pass\n",
    "            else:\n",
    "                print('\\n%60s\\n\\n%s'%(fn, fn_sig))\n",
    "\n",
    "        \n",
    "            \n",
    "def get_functions_dict(file_name):\n",
    "    \"\"\" Usage: function_dict = get_functions_dict(file_name)\n",
    "    Args:\n",
    "        file_name:      full path of python file name\n",
    "    Returns:\n",
    "        function_dict:  function name: function definition string\n",
    "    \"\"\"\n",
    "    fname = os.path.abspath(file_name)\n",
    "    function_dict = {'header': ''}\n",
    "    build_string = ''\n",
    "    header_name = 'header'\n",
    "    last_function_name = header_name\n",
    "    with open(fname, 'r') as fh:\n",
    "        for line in fh:\n",
    "            if \"def \" in line:\n",
    "                function_dict[last_function_name] = build_string\n",
    "                build_string = line\n",
    "                func_name = line.split('(')[0]\n",
    "                func_name = func_name[4:]\n",
    "                function_dict[func_name] = ''\n",
    "                last_function_name = func_name\n",
    "            else:\n",
    "                build_string += line\n",
    "                \n",
    "    return function_dict\n",
    "\n",
    "\n",
    "def dataframe_is_binary(unk_df):\n",
    "    \"\"\" Usage: is_binary = dataframe_is_binary(unk_df)\n",
    "    check matrix to see if the data is all equal to either 1 or 0 \n",
    "    Args:\n",
    "        unk_df:     numerical pandas dataframe of unknown data conformity\n",
    "        \n",
    "    Returns:\n",
    "        is_binary:  True or False (all data is either = 1 or = 0)\n",
    "    \"\"\"\n",
    "    row_size = unk_df.shape[0]\n",
    "    col_size = unk_df.shape[1]\n",
    "    non_binary = 0\n",
    "    for index, row in unk_df.iterrows():\n",
    "        if (int(sum(row == 0)) + int(sum(row == 1))) != col_size:\n",
    "            non_binary += 1\n",
    "    \n",
    "    if non_binary > 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def get_cluster_sets_dict(one_df, column_name=1):\n",
    "    \"\"\" Usage: csd = get_cluster_sets_dict(one_df) \n",
    "    Args:\n",
    "        one_df:         dataframe of labels and clusterings\n",
    "        column_name:    column name to count the clustering\n",
    "    Returns:\n",
    "        clusters_dict:  cluster_number: number_in_cluster\n",
    "    \"\"\"\n",
    "    csd = {}\n",
    "    n_clusters = one_df[column_name].max() + 1\n",
    "    for k in range(0, n_clusters):\n",
    "        s = (one_df[column_name] == k).sum()\n",
    "        csd[k] = s\n",
    "        \n",
    "    return csd\n",
    "\n",
    "def compare_labels(df1, df2, verbose=True):\n",
    "    \"\"\" Usage: eq_count, neq_count = compare_labels(df1, df2) \n",
    "    Args:\n",
    "        df1:        dataframe 1\n",
    "        df2:        dataframe 2 (with same set of labels as dataframe 1)\n",
    "        (verbose):  default True - prints row name differences\n",
    "    Returns:\n",
    "        eq_count:   number of rows that are equal\n",
    "        neq_count:  number of rows that are not equal\n",
    "        \n",
    "    std_out:        prints name of \n",
    "    \"\"\"\n",
    "    eq_count = 0\n",
    "    neq_count = 0\n",
    "    for r in list(df1.index):\n",
    "        if df2[1].loc[r] == df2[1].loc[r]:\n",
    "            eq_count += 1\n",
    "        else:\n",
    "            neq_count += 1\n",
    "            if verbose == True:\n",
    "                print('Not EQ',r ,cmat1[1].loc[r], df2[1].loc[r])\n",
    "            \n",
    "    return eq_count, neq_count\n",
    "\n",
    "def renumber_clusters_by_sort_order(labels_df, column_name=1):\n",
    "    \"\"\" Usage: renumbered_df = renumber_clusters_by_sort_order(labels_df, column_name=1) \n",
    "    Args:\n",
    "        labels_df:      dataframe with no header (labels are index)\n",
    "        column_name:    default = 1\n",
    "    Returns:\n",
    "        renumbered_df:  dataframe with same clustering where the cluster are renumbered in standard way\n",
    "    \"\"\"\n",
    "    clusters_reverse_dict = get_sorted_clustering_reverse_dictionary(labels_df, column_name=1)\n",
    "    renumbered_df = labels_df.copy()\n",
    "    for idx_name in list(labels_df.index):\n",
    "        renumbered_df[column_name].loc[idx_name] = clusters_reverse_dict[labels_df[column_name].loc[idx_name]]\n",
    "        \n",
    "    return renumbered_df\n",
    "\n",
    "def get_sorted_clustering_reverse_dictionary(labels_df, column_name=1):\n",
    "    \"\"\" Usage: clusters_dict = get_sorted_clustering_reverse_dictionary(labels_df, column_name=1) \n",
    "    Args:\n",
    "        labels_df:      labels x cluster_number one column dataframe without header\n",
    "        column_name:    default is first column \n",
    "                        - not tested with multiple cols but expect it would work\n",
    "    Returns:\n",
    "        clusters_dict:  reverse dictionay of cluster-numbers-as-input to cluster-numbers-for-sort-order-labels\n",
    "                        - use to compare labels where different cluster number assignments were used\n",
    "    \"\"\"\n",
    "    n_clusters = labels_df[column_name].max() + 1\n",
    "    cluster_number_dict = {k: k for k in range(0, n_clusters)}\n",
    "    cmat1_dict = labels_df.to_dict()[column_name]\n",
    "\n",
    "    for k, v in cluster_number_dict.items():\n",
    "        for bkey in sorted(list(labels_df.index)):\n",
    "            if labels_df[column_name].loc[bkey] == k:\n",
    "                cluster_number_dict[k] = labels_df[column_name].loc[bkey]\n",
    "                break\n",
    "\n",
    "    return {v: k for k, v in cluster_number_dict.items()}\n",
    "\n",
    "\n",
    "def pipeline_results_compare(results_directory, trim_point):\n",
    "    \"\"\" Usage: differs_dict_of_lists = pipeline_results_compare(results_directory, trim_point) \n",
    "    Args:\n",
    "        results_directory:      with multiple runs of (exactly) the same pipeline\n",
    "        trim_point:             Place to split the time stamp off of the file name e.g. \"_Tue_10\"\n",
    "    Returns:\n",
    "        differs_dict_of_lists:  dict of lists of file that did not match their predicessor\n",
    "    \"\"\"\n",
    "    dir_list = os.listdir(results_directory)\n",
    "    previous_file_name = ''\n",
    "    previous_full_file_name = ''\n",
    "    differs_dict_of_lists = {}\n",
    "    for fn in dir_list:\n",
    "        if previous_file_name == '' or previous_file_name != fn.split(trim_point)[0]:\n",
    "            previous_full_file_name = os.path.join(results_directory, fn)\n",
    "            previous_file_name = fn.split(trim_point)[0]\n",
    "\n",
    "        elif previous_file_name == fn.split(trim_point)[0]:\n",
    "            \n",
    "            if filecmp.cmp(previous_full_file_name, os.path.join(results_directory, fn), shallow=False) != True:\n",
    "\n",
    "                if fn.split(trim_point)[0] in differs_dict_of_lists.keys():\n",
    "                    differs_dict_of_lists[fn.split(trim_point)[0]].append(fn)\n",
    "                else:\n",
    "                    _, pfn = os.path.split(previous_full_file_name)\n",
    "                    differs_dict_of_lists[fn.split(trim_point)[0]] = [pfn]\n",
    "                    differs_dict_of_lists[fn.split(trim_point)[0]].append(fn)\n",
    "                    \n",
    "            previous_full_file_name = os.path.join(results_directory, fn)\n",
    "            previous_file_name = fn.split(trim_point)[0]\n",
    "            \n",
    "    return differs_dict_of_lists\n",
    "\n",
    "def display_pipeline_results_compare(differs_dict_of_lists):\n",
    "    \"\"\" Usage: display a result from pipeline_results_compare function \n",
    "    Args:\n",
    "        differs_dict_of_lists:  return dictionary of mismatched files list from pipeline_results_compare\n",
    "    \"\"\"\n",
    "    for k in list(differs_dict_of_lists.keys()):\n",
    "        print(k,':')\n",
    "        k_list = differs_dict_of_lists[k]\n",
    "        for fn in k_list:\n",
    "            print('\\t',fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/lanier4/git_clone/dlanier/pipe_tools/notebooks/pipeline_output_check.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dd75523871b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline_output_check\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git_clone/dlanier/pipe_tools/src/pipeline_output_check.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pipeline_output_check.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mfunction_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_functions_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_def\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'header'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_clone/dlanier/pipe_tools/src/pipeline_output_check.py\u001b[0m in \u001b[0;36mget_functions_dict\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mheader_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'header'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mlast_function_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheader_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"def \"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/lanier4/git_clone/dlanier/pipe_tools/notebooks/pipeline_output_check.py'"
     ]
    }
   ],
   "source": [
    "#               Module Usage:\n",
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "import pipeline_output_check as pc\n",
    "pc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```run_directory = os.path.abspath('../test')\n",
    "results_directory = os.path.join(run_directory, 'results')\n",
    "trim_point = '_Tue_10'\n",
    "differs_dict_of_lists = pipeline_results_compare(results_directory, trim_point)\n",
    "display_pipeline_results_compare(differs_dict_of_lists)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.NaN == np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                              compare_labels\n",
      "\n",
      "def compare_labels(df1, df2, verbose=True):\n",
      "    \"\"\" Usage: eq_count, neq_count = compare_labels(df1, df2) \n",
      "    Args:\n",
      "        df1:        dataframe 1\n",
      "        df2:        dataframe 2 (with same set of labels as dataframe 1)\n",
      "        (verbose):  default True - prints row name differences\n",
      "    Returns:\n",
      "        eq_count:   number of rows that are equal\n",
      "        neq_count:  number of rows that are not equal\n",
      "        \n",
      "    std_out:        prints name of \n",
      "    \"\"\"\n",
      "    eq_count = 0\n",
      "    neq_count = 0\n",
      "    for r in list(df1.index):\n",
      "        if df2[1].loc[r] == df2[1].loc[r]:\n",
      "            eq_count += 1\n",
      "        else:\n",
      "            neq_count += 1\n",
      "            if verbose == True:\n",
      "                print('Not EQ',r ,cmat1[1].loc[r], df2[1].loc[r])\n",
      "            \n",
      "    return eq_count, neq_count\n",
      "\n",
      "\n",
      "\n",
      "                                                        head\n",
      "\n",
      "def head():\n",
      "    file_name = os.path.join(os.getcwd(), 'pipeline_output_check.py')\n",
      "    function_dict = get_functions_dict(file_name)\n",
      "\n",
      "\n",
      "                            display_pipeline_results_compare\n",
      "\n",
      "\n",
      "\n",
      "                    get_sorted_clustering_reverse_dictionary\n",
      "\n",
      "def get_sorted_clustering_reverse_dictionary(labels_df, column_name=1):\n",
      "    \"\"\" Usage: clusters_dict = get_sorted_clustering_reverse_dictionary(labels_df, column_name=1) \n",
      "    Args:\n",
      "        labels_df:      labels x cluster_number one column dataframe without header\n",
      "        column_name:    default is first column \n",
      "                        - not tested with multiple cols but expect it would work\n",
      "    Returns:\n",
      "        clusters_dict:  reverse dictionay of cluster-numbers-as-input to cluster-numbers-for-sort-order-labels\n",
      "                        - use to compare labels where different cluster number assignments were used\n",
      "    \"\"\"\n",
      "    n_clusters = labels_df[column_name].max() + 1\n",
      "    cluster_number_dict = {k: k for k in range(0, n_clusters)}\n",
      "    cmat1_dict = labels_df.to_dict()[column_name]\n",
      "\n",
      "    for k, v in cluster_number_dict.items():\n",
      "        for bkey in sorted(list(labels_df.index)):\n",
      "            if labels_df[column_name].loc[bkey] == k:\n",
      "                cluster_number_dict[k] = labels_df[column_name].loc[bkey]\n",
      "                break\n",
      "\n",
      "    return {v: k for k, v in cluster_number_dict.items()}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                              show_functions\n",
      "\n",
      "def show_functions(show_defs=False):\n",
      "    \"\"\" Usage: show_functions(show_defs)\n",
      "    Args:       show_defs False is default\n",
      "    \"\"\"\n",
      "    file_name = os.path.join(os.getcwd(), 'pipeline_output_check.py')\n",
      "    function_dict = get_functions_dict(file_name)\n",
      "    if show_defs == False:\n",
      "\n",
      "\n",
      "                                    pipeline_results_compare\n",
      "\n",
      "def pipeline_results_compare(results_directory, trim_point):\n",
      "    \"\"\" Usage: differs_dict_of_lists = pipeline_results_compare(results_directory, trim_point) \n",
      "    Args:\n",
      "        results_directory:      with multiple runs of (exactly) the same pipeline\n",
      "        trim_point:             Place to split the time stamp off of the file name e.g. \"_Tue_10\"\n",
      "    Returns:\n",
      "        differs_dict_of_lists:  dict of lists of file that did not match their predicessor\n",
      "    \"\"\"\n",
      "    dir_list = os.listdir(results_directory)\n",
      "    previous_file_name = ''\n",
      "    previous_full_file_name = ''\n",
      "    differs_dict_of_lists = {}\n",
      "    for fn in dir_list:\n",
      "        if previous_file_name == '' or previous_file_name != fn.split(trim_point)[0]:\n",
      "            previous_full_file_name = os.path.join(results_directory, fn)\n",
      "            previous_file_name = fn.split(trim_point)[0]\n",
      "\n",
      "        elif previous_file_name == fn.split(trim_point)[0]:\n",
      "            \n",
      "            if filecmp.cmp(previous_full_file_name, os.path.join(results_directory, fn), shallow=False) != True:\n",
      "\n",
      "                if fn.split(trim_point)[0] in differs_dict_of_lists.keys():\n",
      "                    differs_dict_of_lists[fn.split(trim_point)[0]].append(fn)\n",
      "                else:\n",
      "                    _, pfn = os.path.split(previous_full_file_name)\n",
      "                    differs_dict_of_lists[fn.split(trim_point)[0]] = [pfn]\n",
      "                    differs_dict_of_lists[fn.split(trim_point)[0]].append(fn)\n",
      "                    \n",
      "            previous_full_file_name = os.path.join(results_directory, fn)\n",
      "            previous_file_name = fn.split(trim_point)[0]\n",
      "            \n",
      "    return differs_dict_of_lists\n",
      "\n",
      "\n",
      "\n",
      "                       for fn, fn_def in function_dict.items\n",
      "\n",
      "        for fn, fn_def in function_dict.items():\n",
      "            if fn in ignore_list:\n",
      "                pass\n",
      "            else:\n",
      "                print('\\n%60s\\n\\n%s'%(fn, fn_sig))\n",
      "\n",
      "        \n",
      "            \n",
      "\n",
      "\n",
      "                                       get_cluster_sets_dict\n",
      "\n",
      "def get_cluster_sets_dict(one_df, column_name=1):\n",
      "    \"\"\" Usage: csd = get_cluster_sets_dict(one_df) \n",
      "    Args:\n",
      "        one_df:         dataframe of labels and clusterings\n",
      "        column_name:    column name to count the clustering\n",
      "    Returns:\n",
      "        clusters_dict:  cluster_number: number_in_cluster\n",
      "    \"\"\"\n",
      "    csd = {}\n",
      "    n_clusters = one_df[column_name].max() + 1\n",
      "    for k in range(0, n_clusters):\n",
      "        s = (one_df[column_name] == k).sum()\n",
      "        csd[k] = s\n",
      "        \n",
      "    return csd\n",
      "\n",
      "\n",
      "\n",
      "                             renumber_clusters_by_sort_order\n",
      "\n",
      "def renumber_clusters_by_sort_order(labels_df, column_name=1):\n",
      "    \"\"\" Usage: renumbered_df = renumber_clusters_by_sort_order(labels_df, column_name=1) \n",
      "    Args:\n",
      "        labels_df:      dataframe with no header (labels are index)\n",
      "        column_name:    default = 1\n",
      "    Returns:\n",
      "        renumbered_df:  dataframe with same clustering where the cluster are renumbered in standard way\n",
      "    \"\"\"\n",
      "    clusters_reverse_dict = get_sorted_clustering_reverse_dictionary(labels_df, column_name=1)\n",
      "    renumbered_df = labels_df.copy()\n",
      "    for idx_name in list(labels_df.index):\n",
      "        renumbered_df[column_name].loc[idx_name] = clusters_reverse_dict[labels_df[column_name].loc[idx_name]]\n",
      "        \n",
      "    return renumbered_df\n",
      "\n",
      "\n",
      "\n",
      "                                         dataframe_is_binary\n",
      "\n",
      "def dataframe_is_binary(unk_df):\n",
      "    \"\"\" Usage: is_binary = dataframe_is_binary(unk_df)\n",
      "    check matrix to see if the data is all equal to either 1 or 0 \n",
      "    Args:\n",
      "        unk_df:     numerical pandas dataframe of unknown data conformity\n",
      "        \n",
      "    Returns:\n",
      "        is_binary:  True or False (all data is either = 1 or = 0)\n",
      "    \"\"\"\n",
      "    row_size = unk_df.shape[0]\n",
      "    col_size = unk_df.shape[1]\n",
      "    non_binary = 0\n",
      "    for index, row in unk_df.iterrows():\n",
      "        if (int(sum(row == 0)) + int(sum(row == 1))) != col_size:\n",
      "            non_binary += 1\n",
      "    \n",
      "    if non_binary > 0:\n",
      "        return False\n",
      "    else:\n",
      "        return True\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                          get_functions_dict\n",
      "\n",
      "def get_functions_dict(file_name):\n",
      "    \"\"\" Usage: function_dict = get_functions_dict(file_name)\n",
      "    Args:\n",
      "        file_name:      full path of python file name\n",
      "    Returns:\n",
      "        function_dict:  function name: function definition string\n",
      "    \"\"\"\n",
      "    fname = os.path.abspath(file_name)\n",
      "    function_dict = {'header': ''}\n",
      "    build_string = ''\n",
      "    header_name = 'header'\n",
      "    last_function_name = header_name\n",
      "    with open(fname, 'r') as fh:\n",
      "        for line in fh:\n",
      "\n",
      "\n",
      "                       for fn, fn_def in function_dict.items\n",
      "\n",
      "    for fn, fn_def in function_dict.items():\n",
      "        if fn == 'header':\n",
      "            print('\\n%60s\\n\\n%s'%(fn, fn_sig))\n",
      "            \n",
      "\n",
      "\n",
      "                                         if \"def \" in line:\n",
      "\n",
      "\n",
      "            if \"def \" in line:\n",
      "                function_dict[last_function_name] = build_string\n",
      "                build_string = line\n",
      "                func_name = line.split('(')[0]\n",
      "                func_name = func_name[4:]\n",
      "                function_dict[func_name] = ''\n",
      "                last_function_name = func_name\n",
      "            else:\n",
      "                build_string += line\n",
      "                \n",
      "    return function_dict\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_name = 'pipeline_output_check.py'\n",
    "fname = os.path.abspath(os.path.join('../src', file_name))\n",
    "\n",
    "function_dict = get_functions_dict(fname)\n",
    "for fn, fn_sig in function_dict.items():\n",
    "    if fn == 'header':\n",
    "        pass\n",
    "    else:\n",
    "        print('\\n%60s\\n\\n%s'%(fn, fn_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "42px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
