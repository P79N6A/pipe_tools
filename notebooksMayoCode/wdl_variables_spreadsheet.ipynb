{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SomaticVC',\n",
       " 'DeliveryOfSomaticVC',\n",
       " 'GermlineMasterWorkflow.wdl',\n",
       " 'config_vars.ipynb',\n",
       " 'Alignment',\n",
       " '.ipynb_checkpoints',\n",
       " 'SomaticMasterWorkflow.wdl',\n",
       " 'DeliveryOfHaplotyperVC',\n",
       " 'DeliveryOfAlignment',\n",
       " 'HaplotyperVC']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# pandas quard\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "clone_base = '/Users/mojo/git_clone/SAM_BAM/'\n",
    "wdl_directory = os.path.join(clone_base,'MayomicsVC/src/wdl')\n",
    "os.listdir(wdl_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code example: Check the possible types in \"task\" section:\n",
    "```python\n",
    "skip_line_chars = ['#', '<', '>']\n",
    "switch_ON_words = ['task']\n",
    "switch_OFF_words = ['command', 'runtime', 'output']\n",
    "add_words_ON = False\n",
    "\n",
    "first_words = []\n",
    "for this_dir, dirs, files in os.walk(wdl_directory):\n",
    "    for file in files:\n",
    "        if file[-4:] == '.wdl':\n",
    "            add_words_ON = False\n",
    "            full_filename = os.path.join(this_dir, file)\n",
    "            with open(full_filename, 'r') as fh:\n",
    "                lines = fh.readlines()\n",
    "            for line in lines:\n",
    "                l = line.strip()\n",
    "                if len(l) > 0 and not l[0] in skip_line_chars:\n",
    "                    first_word = l.split()[0]\n",
    "                    if first_word in switch_OFF_words:\n",
    "                        add_words_ON = False\n",
    "                    if add_words_ON == True:\n",
    "                        first_words.append(first_word)\n",
    "                    if first_word in switch_ON_words:\n",
    "                        add_words_ON = True\n",
    "\n",
    "first_words = sorted(list(set(first_words)))\n",
    "print('There are %i unique types in all the wdl files:'%(len(first_words)))\n",
    "for wurd in first_words:\n",
    "    print('\\t',wurd)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 116 variables\n",
      "                      Adapters:               \"File\"\n",
      "               AlignEnvProfile:               \"File\"\n",
      "             AlignHardMemLimit:             \"String\"\n",
      "               AlignOutputBais:        \"Array[File]\"\n",
      "               AlignOutputBams:        \"Array[File]\"\n",
      "             AlignSoftMemLimit:             \"String\"\n",
      "               AlignmentScript:               \"File\"\n",
      "                  AnnotateText:             \"String\"\n",
      "         BWAExtraOptionsString:             \"String\"\n",
      "                  BashPreamble:               \"File\"\n",
      "           BashSharedFunctions:               \"File\"\n",
      "                          Bqsr:            \"Boolean\"\n",
      "                BqsrEnvProfile:               \"File\"\n",
      "              BqsrHardMemLimit:             \"String\"\n",
      "                BqsrKnownSites:             \"String\"\n",
      "                    BqsrScript:               \"File\"\n",
      "              BqsrSoftMemLimit:             \"String\"\n",
      "                    CenterName:             \"String\"\n",
      "              ChunkSizeInBases:             \"String\"\n",
      "                      CutAdapt:             \"String\"\n",
      "               CutAdaptThreads:             \"String\"\n",
      "                         DBSNP:               \"File\"\n",
      "                      DBSNPIdx:               \"File\"\n",
      "                     DebugMode:             \"String\"\n",
      "               DedupEnvProfile:               \"File\"\n",
      "             DedupHardMemLimit:             \"String\"\n",
      "                   DedupScript:               \"File\"\n",
      "             DedupSoftMemLimit:             \"String\"\n",
      "        DeliverAlignOutputBais:               \"File\"\n",
      "        DeliverAlignOutputBams:               \"File\"\n",
      "          DeliverHaplotyperVcf:               \"File\"\n",
      "       DeliverHaplotyperVcfIdx:               \"File\"\n",
      "      DeliveryAlignment_Script:               \"File\"\n",
      "      DeliveryFolder_Alignment:             \"String\"\n",
      "   DeliveryFolder_HaplotyperVC:             \"String\"\n",
      "      DeliveryFolder_SomaticVC:             \"String\"\n",
      "   DeliveryHaplotyperVC_Script:               \"File\"\n",
      "      DeliverySomaticVC_Script:               \"File\"\n",
      " GlobalAlignedSortedDedupedBam:               \"File\"\n",
      "GlobalAlignedSortedDedupedBamBai:               \"File\"\n",
      "         GlobalRecalibratedVcf:               \"File\"\n",
      "      GlobalRecalibratedVcfIdx:               \"File\"\n",
      "          HaplotyperEnvProfile:               \"File\"\n",
      "  HaplotyperExtraOptionsString:             \"String\"\n",
      "        HaplotyperHardMemLimit:             \"String\"\n",
      "              HaplotyperScript:               \"File\"\n",
      "        HaplotyperSoftMemLimit:             \"String\"\n",
      "                     InputBais: \"File, Array[File], File, File, File, File\"\n",
      "                     InputBams: \"File, Array[File], File, File, File, File\"\n",
      "                InputMutectVcf:               \"File\"\n",
      "             InputMutectVcfIdx:               \"File\"\n",
      "                    InputRead1:               \"File\"\n",
      "                    InputRead2:             \"String\"\n",
      "               InputStrelkaVcf:               \"File\"\n",
      "            InputStrelkaVcfIdx:               \"File\"\n",
      "                      InputVcf:               \"File\"\n",
      "                   InputVcfIdx:               \"File\"\n",
      "                       Library:             \"String\"\n",
      "                MarkDuplicates:            \"Boolean\"\n",
      "            MergeBamEnvProfile:               \"File\"\n",
      "                MergeBamScript:               \"File\"\n",
      "             MergeHardMemLimit:             \"String\"\n",
      "             MergeSoftMemLimit:             \"String\"\n",
      "     MergeSomaticVcfEnvProfile:               \"File\"\n",
      "         MergeSomaticVcfScript:               \"File\"\n",
      "                        Mutect:             \"String\"\n",
      "              MutectEnvProfile:               \"File\"\n",
      "      MutectExtraOptionsString:             \"String\"\n",
      "                  MutectScript:               \"File\"\n",
      "                 MutectThreads:             \"String\"\n",
      "                    NormalBais:               \"File\"\n",
      "                    NormalBams:               \"File\"\n",
      "                    OutputBais: \"File, Array[File], File, File\"\n",
      "                    OutputBams: \"File, Array[File], File, File\"\n",
      "                     OutputVcf:               \"File\"\n",
      "                  OutputVcfIdx:               \"File\"\n",
      "                       Outputs:        \"Array[File]\"\n",
      "                     PairedEnd:            \"Boolean\"\n",
      "                      Platform:             \"String\"\n",
      "                  PlatformUnit:             \"String\"\n",
      "             RealignEnvProfile:               \"File\"\n",
      "           RealignHardMemLimit:             \"String\"\n",
      "           RealignSoftMemLimit:             \"String\"\n",
      "         RealignmentKnownSites:             \"String\"\n",
      "             RealignmentScript:               \"File\"\n",
      "                    RecalTable:        \"File?, File\"\n",
      "                           Ref:               \"File\"\n",
      "                        RefAmb:               \"File\"\n",
      "                        RefAnn:               \"File\"\n",
      "                        RefBwt:               \"File\"\n",
      "                        RefFai:               \"File\"\n",
      "                        RefPac:               \"File\"\n",
      "                         RefSa:               \"File\"\n",
      "                    SampleName:             \"String\"\n",
      "                      Sentieon:             \"String\"\n",
      "               SentieonThreads:             \"String\"\n",
      "                       Strelka:             \"String\"\n",
      "             StrelkaEnvProfile:               \"File\"\n",
      "     StrelkaExtraOptionsString:             \"String\"\n",
      "                 StrelkaScript:               \"File\"\n",
      "                StrelkaThreads:             \"String\"\n",
      "                TrimEnvProfile:               \"File\"\n",
      "              TrimHardMemLimit:             \"String\"\n",
      "                 TrimSeqScript:               \"File\"\n",
      "              TrimSoftMemLimit:             \"String\"\n",
      "                      Trimming:            \"Boolean\"\n",
      "                     TumorBais:               \"File\"\n",
      "                     TumorBams:               \"File\"\n",
      "                          Vqsr:            \"Boolean\"\n",
      "                VqsrEnvProfile:               \"File\"\n",
      "              VqsrHardMemLimit:             \"String\"\n",
      "       VqsrIndelResourceString:             \"String\"\n",
      "                    VqsrScript:               \"File\"\n",
      "         VqsrSnpResourceString:             \"String\"\n",
      "              VqsrSoftMemLimit:             \"String\"\n",
      "                  WorkflowJson:               \"File\"\n"
     ]
    }
   ],
   "source": [
    "def get_wdl_variables_dict(wdl_directory=None):\n",
    "    # Get the complete config.txt file:\n",
    "    skip_line_chars = ['#', '<', '>']\n",
    "    task_types_list = sorted(['Array[File]', 'File', 'File?', 'Boolean', 'String'])\n",
    "    config_vars_dict = {}\n",
    "    for this_dir, dirs, files in os.walk(wdl_directory):\n",
    "        for file in files:\n",
    "            if file[-4:] == '.wdl' and file[0] != '.':\n",
    "                full_filename = os.path.join(this_dir, file)\n",
    "                with open(full_filename, 'r') as fh:\n",
    "                    lines = fh.readlines()\n",
    "                for line in lines:\n",
    "                    l = line.strip()\n",
    "                    if len(l) > 0 and not l[0] in skip_line_chars:\n",
    "                        line_words_list = l.split()\n",
    "                        first_word = line_words_list[0]\n",
    "                        if first_word in task_types_list:\n",
    "                            second_word = line_words_list[1]\n",
    "                            if not second_word in config_vars_dict.keys():\n",
    "                                config_vars_dict[second_word] = '\"' + first_word + '\"'\n",
    "                                \n",
    "                            elif first_word != config_vars_dict[second_word][1:-1]:\n",
    "                                bugger = config_vars_dict[second_word][:-1]\n",
    "                                config_vars_dict[second_word] = bugger + ', ' + first_word  + '\"'\n",
    "                                \n",
    "    config_od = OrderedDict()\n",
    "    for k, v in sorted(config_vars_dict.items()):\n",
    "        config_od[k] = v\n",
    "\n",
    "    return config_od\n",
    "\n",
    "config_vars_dict_ret = get_wdl_variables_dict(wdl_directory)\n",
    "print('found %i variables'%(len(config_vars_dict_ret)))\n",
    "config_od = OrderedDict()\n",
    "for k, v in sorted(config_vars_dict_ret.items()):\n",
    "    config_od[k] = v\n",
    "    \n",
    "for k, v in config_od.items():\n",
    "    print('%30s: %20s'%(k,v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wdl_files_spreadsheet(wdl_directory=None):\n",
    "    \"\"\" get the section statistics for a directory tree of wdl files \"\"\"\n",
    "    if not wdl_directory is None and os.path.isdir(wdl_directory):\n",
    "        may_dir = wdl_directory\n",
    "    else:\n",
    "        may_dir = os.getcwd()\n",
    "    \n",
    "    dir_name_stripper, _ = os.path.split(wdl_directory)\n",
    "\n",
    "    prefix_ignores = ['.', '_']\n",
    "    \n",
    "    # assemble dictionary - wdl file names: full path  -------- Build empty pandas dataframe\n",
    "    mdl_dict = {}\n",
    "    for dir_name, dir_list, files_list in os.walk(may_dir):\n",
    "        if len(files_list) > 0:\n",
    "            for file_name in files_list:\n",
    "                if file_name[-4:] == '.wdl' and file_name[0] not in prefix_ignores:\n",
    "                    mdl_dict[file_name] = os.path.join(dir_name, file_name)\n",
    "    wdl_df = pd.DataFrame.from_dict(mdl_dict, orient='index', columns=['src_path'])\n",
    "    wdl_df.index.name = 'WDL file'\n",
    "    \n",
    "    # define the rest of the columns in terms of wdl keywords\n",
    "    srch_dict = OrderedDict([('imports','import'), \n",
    "                             ('workflows','workflow'), \n",
    "                            ('tasks','task'), \n",
    "                            ('inputs','input'), \n",
    "                            ('outputs','output'),\n",
    "                            ('commands', 'command')])\n",
    "    for col_name, _ in srch_dict.items():\n",
    "        wdl_df[col_name] = 0\n",
    "\n",
    "    # for each wdl file: count keywords, get top path ---------- fill pandas dataframe\n",
    "    for name, row in wdl_df.iterrows():\n",
    "        \"\"\" using row.src_path to open files and name to refer to row in dataframe \"\"\"\n",
    "        lines = []\n",
    "        try:\n",
    "            with open(row.src_path, 'r') as fh:\n",
    "                lines = fh.readlines()\n",
    "        except:\n",
    "            print('Fails to open:\\n', row.src_path)\n",
    "            pass\n",
    "        \n",
    "        # count & insert occurrence of keywords\n",
    "        if len(lines) > 0:\n",
    "            for l in lines:\n",
    "                for col_name, key_word in srch_dict.items():\n",
    "                    if key_word in l:\n",
    "                        wdl_df[col_name].loc[name] += 1\n",
    "\n",
    "        # replace the full path name with top path name for readability\n",
    "        full_path, _ = os.path.split(mdl_dict[name])\n",
    "        wdl_df['src_path'].loc[name] = full_path.replace(dir_name_stripper, '..')\n",
    "        \n",
    "    return wdl_df\n",
    "\n",
    "wdl_df = get_wdl_files_spreadsheet(wdl_directory)\n",
    "print(wdl_df.shape)\n",
    "wdl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Usage:\n",
    "python ~/python/check_return_codes.py -d /projects/mgc/Project_1/DEL/MVP/cromwell-executions/GermlineMasterWF/\n",
    "or \n",
    "python ~/python/check_return_codes.py -d `pwd`\n",
    "\n",
    "check return codes in directory tree\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "good_return_codes_list = ['0', '0\\n']\n",
    "\n",
    "def check_rc_codes(x_directory=None):\n",
    "    if not x_directory is None and os.path.isdir(x_directory):\n",
    "        dir_tree_root = x_directory\n",
    "    else:\n",
    "        dir_tree_root = os.getcwd()\n",
    "    root_trim_str, _ = os.path.split(dir_tree_root)\n",
    "    for dir_name, dir_list, files_list in os.walk(dir_tree_root):\n",
    "        for filename in files_list:\n",
    "            if filename == 'rc':\n",
    "                full_filename = os.path.join(dir_name, filename)\n",
    "                with open(full_filename, 'r') as fh:\n",
    "                    lines = fh.readlines()\n",
    "                if lines[0] in good_return_codes_list:\n",
    "                    top_dir = dir_name.replace(root_trim_str, '..')\n",
    "                    print('good rc:  %s'%(top_dir))\n",
    "                else:\n",
    "                    print('\\n\\tBad Dog! Bad Dog!')\n",
    "                    print('code = %s in \\n%s'%(str(lines[0]).strip(), full_filename))\n",
    "                    print('\\tBad Dog! Bad Dog!\\n')\n",
    "                    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', type=str)\n",
    "    args = parser.parse_args()\n",
    "    check_rc_codes(args.d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
