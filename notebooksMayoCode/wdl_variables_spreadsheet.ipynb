{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SomaticVC',\n",
       " 'DeliveryOfSomaticVC',\n",
       " 'GermlineMasterWorkflow.wdl',\n",
       " 'config_vars.ipynb',\n",
       " 'Alignment',\n",
       " '.ipynb_checkpoints',\n",
       " 'SomaticMasterWorkflow.wdl',\n",
       " 'DeliveryOfHaplotyperVC',\n",
       " 'DeliveryOfAlignment',\n",
       " 'HaplotyperVC']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "clone_base = '/Users/mojo/git_clone/SAM_BAM/'\n",
    "wdl_directory = os.path.join(clone_base,'MayomicsVC/src/wdl')\n",
    "os.listdir(wdl_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 unique types in all the wdl files:\n",
      "\t Array[File]\n",
      "\t Boolean\n",
      "\t File\n",
      "\t File?\n",
      "\t String\n",
      "\t task\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all tpyes in the tasks section of the wdl files:\n",
    "skip_line_chars = ['#', '<', '>']\n",
    "switch_ON_words = ['task']\n",
    "switch_OFF_words = ['command', 'runtime', 'output']\n",
    "add_words_ON = False\n",
    "\n",
    "first_words = []\n",
    "for this_dir, dirs, files in os.walk(wdl_directory):\n",
    "    for file in files:\n",
    "        if file[-4:] == '.wdl':\n",
    "            full_filename = os.path.join(this_dir, file)\n",
    "            with open(full_filename, 'r') as fh:\n",
    "                lines = fh.readlines()\n",
    "            for line in lines:\n",
    "                l = line.strip()\n",
    "                if len(l) > 0 and not l[0] in skip_line_chars:\n",
    "                    first_word = l.split()[0]\n",
    "                    if first_word in switch_OFF_words:\n",
    "                        add_words_ON = False\n",
    "                    if first_word in switch_ON_words:\n",
    "                        add_words_ON = True\n",
    "                    if add_words_ON == True:\n",
    "                        first_words.append(first_word)\n",
    "\n",
    "first_words = sorted(list(set(first_words)))\n",
    "print('There are %i unique types in all the wdl files:'%(len(first_words)))\n",
    "for wurd in first_words:\n",
    "    print('\\t',wurd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 130 variables\n",
      "                      Trimming: \"Boolean\"\n",
      "                MarkDuplicates: \"Boolean\"\n",
      "                          Bqsr: \"Boolean\"\n",
      "                          Vqsr: \"Boolean\"\n",
      "        DeliverAlignOutputBams: \"File\"\n",
      "        DeliverAlignOutputBais: \"File\"\n",
      "          DeliverHaplotyperVcf: \"File\"\n",
      "       DeliverHaplotyperVcfIdx: \"File\"\n",
      "                   strelkaTask: \"task\"\n",
      "                     TumorBams: \"File\"\n",
      "                     TumorBais: \"File\"\n",
      "                    NormalBams: \"File\"\n",
      "                    NormalBais: \"File\"\n",
      "                           Ref: \"File\"\n",
      "                        RefFai: \"File\"\n",
      "                    SampleName: \"String\"\n",
      "     StrelkaExtraOptionsString: \"String\"\n",
      "                       Strelka: \"String\"\n",
      "                StrelkaThreads: \"String\"\n",
      "                  BashPreamble: \"File\"\n",
      "           BashSharedFunctions: \"File\"\n",
      "                 StrelkaScript: \"File\"\n",
      "             StrelkaEnvProfile: \"File\"\n",
      "                     DebugMode: \"String\"\n",
      "                     OutputVcf: \"File\"\n",
      "                  OutputVcfIdx: \"File\"\n",
      "           mergeSomaticVcfTask: \"task\"\n",
      "               InputStrelkaVcf: \"File\"\n",
      "            InputStrelkaVcfIdx: \"File\"\n",
      "                InputMutectVcf: \"File\"\n",
      "             InputMutectVcfIdx: \"File\"\n",
      "         MergeSomaticVcfScript: \"File\"\n",
      "     MergeSomaticVcfEnvProfile: \"File\"\n",
      "                    mutectTask: \"task\"\n",
      "      MutectExtraOptionsString: \"String\"\n",
      "                        Mutect: \"String\"\n",
      "                 MutectThreads: \"String\"\n",
      "                  MutectScript: \"File\"\n",
      "              MutectEnvProfile: \"File\"\n",
      "          deliverSomaticVCTask: \"task\"\n",
      "                      InputVcf: \"File\"\n",
      "                   InputVcfIdx: \"File\"\n",
      "                  WorkflowJson: \"File\"\n",
      "      DeliverySomaticVC_Script: \"File\"\n",
      "      DeliveryFolder_SomaticVC: \"String\"\n",
      "             trimsequencesTask: \"task\"\n",
      "                    InputRead1: \"File\"\n",
      "                    InputRead2: \"String\"\n",
      "                      Adapters: \"File\"\n",
      "                      CutAdapt: \"String\"\n",
      "               CutAdaptThreads: \"String\"\n",
      "                     PairedEnd: \"Boolean\"\n",
      "                 TrimSeqScript: \"File\"\n",
      "                TrimEnvProfile: \"File\"\n",
      "              TrimSoftMemLimit: \"String\"\n",
      "              TrimHardMemLimit: \"String\"\n",
      "                       Outputs: \"Array[File]\"\n",
      "                     dedupTask: \"task\"\n",
      "                     InputBams: \"File_Array[File]_File_File_File_File\"\n",
      "                     InputBais: \"File_Array[File]_File_File_File_File\"\n",
      "                      Sentieon: \"String\"\n",
      "               SentieonThreads: \"String\"\n",
      "             DedupSoftMemLimit: \"String\"\n",
      "             DedupHardMemLimit: \"String\"\n",
      "                   DedupScript: \"File\"\n",
      "               DedupEnvProfile: \"File\"\n",
      "                    OutputBams: \"File_Array[File]_File_File\"\n",
      "                    OutputBais: \"File_Array[File]_File_File\"\n",
      "                  mergebamTask: \"task\"\n",
      "             MergeSoftMemLimit: \"String\"\n",
      "             MergeHardMemLimit: \"String\"\n",
      "                MergeBamScript: \"File\"\n",
      "            MergeBamEnvProfile: \"File\"\n",
      "                 alignmentTask: \"task\"\n",
      "                      Platform: \"String\"\n",
      "                       Library: \"String\"\n",
      "                  PlatformUnit: \"String\"\n",
      "                    CenterName: \"String\"\n",
      "                        RefAmb: \"File\"\n",
      "                        RefAnn: \"File\"\n",
      "                        RefBwt: \"File\"\n",
      "                        RefPac: \"File\"\n",
      "                         RefSa: \"File\"\n",
      "               AlignmentScript: \"File\"\n",
      "               AlignEnvProfile: \"File\"\n",
      "              ChunkSizeInBases: \"String\"\n",
      "         BWAExtraOptionsString: \"String\"\n",
      "             AlignSoftMemLimit: \"String\"\n",
      "             AlignHardMemLimit: \"String\"\n",
      "               AlignOutputBams: \"Array[File]\"\n",
      "               AlignOutputBais: \"Array[File]\"\n",
      "       deliverHaplotyperVCTask: \"task\"\n",
      "   DeliveryHaplotyperVC_Script: \"File\"\n",
      "   DeliveryFolder_HaplotyperVC: \"String\"\n",
      "         GlobalRecalibratedVcf: \"File\"\n",
      "      GlobalRecalibratedVcfIdx: \"File\"\n",
      "          deliverAlignmentTask: \"task\"\n",
      "      DeliveryAlignment_Script: \"File\"\n",
      "      DeliveryFolder_Alignment: \"String\"\n",
      " GlobalAlignedSortedDedupedBam: \"File\"\n",
      "GlobalAlignedSortedDedupedBamBai: \"File\"\n",
      "               realignmentTask: \"task\"\n",
      "         RealignmentKnownSites: \"String\"\n",
      "           RealignSoftMemLimit: \"String\"\n",
      "           RealignHardMemLimit: \"String\"\n",
      "             RealignmentScript: \"File\"\n",
      "             RealignEnvProfile: \"File\"\n",
      "            variantCallingTask: \"task\"\n",
      "                    RecalTable: \"File?_File\"\n",
      "  HaplotyperExtraOptionsString: \"String\"\n",
      "                         DBSNP: \"File\"\n",
      "                      DBSNPIdx: \"File\"\n",
      "        HaplotyperSoftMemLimit: \"String\"\n",
      "        HaplotyperHardMemLimit: \"String\"\n",
      "              HaplotyperScript: \"File\"\n",
      "          HaplotyperEnvProfile: \"File\"\n",
      "                      bqsrTask: \"task\"\n",
      "                BqsrKnownSites: \"String\"\n",
      "              BqsrSoftMemLimit: \"String\"\n",
      "              BqsrHardMemLimit: \"String\"\n",
      "                    BqsrScript: \"File\"\n",
      "                BqsrEnvProfile: \"File\"\n",
      "                      vqsrTask: \"task\"\n",
      "         VqsrSnpResourceString: \"String\"\n",
      "       VqsrIndelResourceString: \"String\"\n",
      "                  AnnotateText: \"String\"\n",
      "              VqsrSoftMemLimit: \"String\"\n",
      "              VqsrHardMemLimit: \"String\"\n",
      "                    VqsrScript: \"File\"\n",
      "                VqsrEnvProfile: \"File\"\n"
     ]
    }
   ],
   "source": [
    "# Get the complete config.txt file:\n",
    "config_vars_dict = {}\n",
    "for this_dir, dirs, files in os.walk(wdl_directory):\n",
    "    for file in files:\n",
    "        if file[-4:] == '.wdl' and file[0] != '.':\n",
    "            full_filename = os.path.join(this_dir, file)\n",
    "            with open(full_filename, 'r') as fh:\n",
    "                lines = fh.readlines()\n",
    "            for line in lines:\n",
    "                l = line.strip()\n",
    "                if len(l) > 0 and not l[0] in skip_line_chars:\n",
    "                    line_words_list = l.split()\n",
    "                    first_word = line_words_list[0]\n",
    "                    if first_word in first_words:\n",
    "                        second_word = line_words_list[1]\n",
    "                        if not second_word in config_vars_dict.keys():\n",
    "                            config_vars_dict[second_word] = '\"' + first_word + '\"'\n",
    "                        elif first_word != config_vars_dict[second_word][1:-1]:\n",
    "                            bugger = config_vars_dict[second_word][:-1]\n",
    "                            config_vars_dict[second_word] = bugger + '_' + first_word  + '\"'\n",
    "                            \n",
    "print('found %i variables'%(len(config_vars_dict)))\n",
    "for k, v in config_vars_dict.items():\n",
    "    print('%30s: %s'%(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
